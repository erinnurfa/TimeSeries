# -*- coding: utf-8 -*-
"""m515y1092_Erin_TimeSeries3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xk2NOnggYqsKqIJo3PzsS9cF6nSC9VYl

Nama : Erin Nur Fatimah

Id : M515Y1092

Path : Pengembang Machine Learning dan Front-End (M02)

No WhatsApp : 083149731170

Email : 203110024@students.akakom.ac.id
"""

from google.colab import drive

drive.mount('/content/drive')

import numpy as np
import pandas as pd
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

dfr = pd.read_csv('/content/drive/MyDrive/data set/data set proyek 2/daily-minimum-temperatures-in-me.csv')
dfr

dfr.isnull().any()

dates = dfr['Date'].values
temp = dfr['Daily minimum temperatures'].values
data = temp.reshape(-1, 1)

scaler = MinMaxScaler()
label = scaler.fit(data)
label = scaler.fit_transform(data)
label = label.flatten()
label

plt.figure(figsize=(15,5), dpi=100)
plt.plot(dates, label)
plt.title('Rata Rata Suhu',
          fontsize=18);

data_main, data_test, label_main, label_test = train_test_split(label, dates, test_size=0.2)  
data_latih, data_val, label_latih, label_val = train_test_split(data_main, label_main, test_size=0.2)  
data_latih

def windowed_data(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[-1:]))
    return ds.batch(batch_size).prefetch(1)

train_set = windowed_data(data_latih, window_size=100, batch_size=100, shuffle_buffer=1000)
val_set = windowed_data(data_test, window_size=100, batch_size=100, shuffle_buffer=1000)
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv1D(filters=100, kernel_size=100, strides=2,padding="causal", activation="relu", input_shape=[None, 1]),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(120, return_sequences=True)),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(120)),
    tf.keras.layers.Dense(1),
])

threshold = (dfr['Daily minimum temperatures'].max()-dfr['Daily minimum temperatures'].min())*10/100
threshold

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae') < threshold):
      print("\nmae lebih kecil dari 10% data. maka training berhenti!")
      self.model.stop_training = True

callbacks = myCallback()

optimizer = tf.keras.optimizers.Adam(learning_rate=.01, decay=.01)
model.compile(
            loss=tf.keras.losses.Huber(),
            optimizer=optimizer,
            metrics=["mae"])
history = model.fit(train_set,epochs=500)

plt.plot(history.history['mae'], label="Mae")
plt.title('GRAFIK')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend(loc='upper right')
plt.show()